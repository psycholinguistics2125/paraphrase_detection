data_folder:  "/home/robin/Code_repo/psycholinguistic2125/paraphrase_detection/data/"
agg_file : "/home/robin/Code_repo/psycholinguistic2125/paraphrase_detection/data/corpus/20240928_aggregated_database_gpt-3.5-turbo_gpt2_pythia_features.pkl" #20240207_aggregated_database.pkl
data_isaac : 
  folder : "/home/robin/Data/Etude_isaac"
  stories_file : "clean_stories.csv"
  scores_file : "factorScores_1.csv"
  features_file : "20241005_features.pkl"
  items_file : "itemsForRobin.csv"
generate_dataset:
  saving_folder: "data/corpus"
  dataset_name: "dataset_20240928.csv"
  model_name : "pythia" # "gpt2" or "falcon-1b" or pythia
  prompt_list : ["Most people start the day by", 
    "Today I am feeling", 
    "The thing I like most in the world is",
    "When I was a little kid", 
    "I had a terrifying dream last night in which",
    "I worry a lot about"]
  n_simulations : 200 # number of simulation by prompt
  target_length : 200 # max length of the generated text
  min_temperature : 4
  max_temperature : 5
  top_p:  0.95
  top_k:  50
  retrospective_span: 200
  online : False # if True, the model will generate paraphrase online

paraphrase_dataset:
  source_dataset: "data/corpus/gpt2_dataset.csv"
  saving_folder: "data/altered_corpus"
  model_name: "gpt-3.5-turbo" #"ibm/qcpg-sentences"
  paraphrase_generator:
    # Default model for ParaphraseGenerator
    default_model: "ibm/qcpg-sentences"

  paraphrase_models:
    - "Vamsi/T5_Paraphrase_Paws"
    - "umarin/chatgpt_paraphraser_on_T5_base"
    - "prithivida/parrot_paraphraser_on_T5"
    - "stanford-oval/paraphraser-bart-large"

  quality_control_models:
    - "ibm/qcpg-sentences"
    - "ibm/qcpg-captions"
    - "ibm/qcpg-questions"

  open_ai_models:
    - "gpt-3.5-turbo"
    - "text-davinci-002"

  parrot_kwargs:
    diversity_ranker: "levenshtein"
    do_diverse: 9
    max_return_phrases: 10
    adequacy_threshold: 0.1
    fluency_threshold: 0.1

  quality_control_kwargs:
    lexical: 0.6
    syntactic: 0.5
    semantic: 0.8
  
  openai_kwargs:
    max_tokens: 200
    temperature: 0.9


online_param:
  nb_paraphrase_max : 1 #nb of paraphrase to generate during the process max
  p_paraphrase : 0.1 #probability to paraphrase at each step
  q_paraphrase: 0.1 # probability to paraphrase close
  alpha : 0.5 # parameter of the pareto distribution

similarity_param:
  model_name: "w2v" #fast_text
  model_folder : "/home/robin/Code_repo/psycholinguistic2125/paraphrase_detection/models"